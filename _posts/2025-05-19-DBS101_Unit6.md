---
Title: DBS101 Unit 6
categories: [DBS101, Unit6]
tags: [DBS101]
---

# Topic: Unit 6
---

## Lesson 14: Indexing Techniques for Faster Data Retrieval

###  What Are Indexes?

   Indexes are specialized data structures that act like “lookup tables” for databases, drastically speeding up query performance. Without indexes, databases would perform full table scans for every query, which is inefficient for large datasets.

### Types of Indexes

#### 1.Ordered Indices:
- Organize data by sorted keys.

   - Clustering Index: Stores records in the same order as the index (often used with primary keys).
Non-Clustering (Secondary) Index: Indexes non-key attributes, requiring pointers to all matching records.

   - Dense vs. Sparse Indexes:
Dense: An entry for every search key (e.g., CREATE INDEX ON employees(emp_id);).

   - Sparse: Entries for only some keys, suitable for sorted data (e.g., CREATE INDEX employees_sparse_idx ON employees(salary) WITH (fillfactor=100);).

#### 2.Hashed Indices:
- Use hash functions to map keys to “buckets,” ideal for equality searches (e.g., SELECT * FROM users WHERE id = 2;).
Fast for exact matches but poor for range queries.

#### 3.B-Tree Family:

  - B-Tree: A balanced tree allowing multiple keys per node, reducing disk accesses for large datasets.

  - B+ Tree: Optimized for disk systems, with keys in internal nodes and data only in leaf nodes, enabling efficient range queries.

#### Multilevel Indexing:

   - When indexes are too large for memory, multilevel indexing creates an “index on the index.” An outer index (in memory) points to blocks of an inner index (on disk), reducing disk I/O during searches.

## Lesson 15: Query Processing: From SQL to Execution

### What Is Query Processing?
Query processing translates high-level SQL queries into efficient low-level operations. It involves three main stages:

#### 1.Parsing and Translation:
- Convert SQL to a relational algebra expression (e.g., a parse tree).
Example: SELECT * FROM employees WHERE salary < 75000 becomes a selection operation on the employees table.

#### 2.Optimization:
  - Choose the cheapest execution plan by evaluating factors like CPU and I/O costs.

  - Key Techniques:
    - Pipelining: Execute operations consecutively without writing intermediate results to disk, reducing I/O.
    - Materialization: Store intermediate results temporarily (useful for complex queries).

#### 3.Execution:
- Use algorithms like nested-loop join, merge join, or hash join to process data.
- Cost Metrics:
Traditional focus on I/O cost (block transfers and seeks), but modern systems consider CPU cost for in-memory data.
   - Example: A nested-loop join on two tables may require N * M tuple comparisons, while a block nested-loop join reduces this by processing blocks instead of tuples.
## Lesson 16: Query Optimization: Crafting Efficient Plans
### Goal: 
Select the optimal query execution plan using equivalence rules and cost-based analysis.

#### Equivalence Rules:
- Rewrite queries without changing results but
  improving efficiency:

- Commutativity: 
  - Rearrange selections or joins (e.g., σθ1(σθ2(E)) ≡ σθ2(σθ1(E))).
Distribution: Push selections into joins (e.g., σθ(E1 ⋈ E2) ≡ (σθ(E1)) ⋈ E2 if the condition applies to E1).

#### Join Ordering:
- The order of joining tables significantly impacts performance. For example:

- Joining smaller intermediate results first (e.g., filtering early) reduces data size.
- Example: Join (instructor ⋈ teaches) ⋈ course instead of (instructor ⋈ course) ⋈ teaches to avoid large intermediate sets.

#### Cost-Based Optimization:

- Use statistics (e.g., table sizes, index availability) to estimate plan costs.
- Explore join orders and algorithms (e.g., nested loop vs. merge join) to find the lowest-cost plan.

#### Heuristics and Tips:

- Early Selection/Projection: Filter and project data early to reduce input size.

- Avoid Nested Subqueries: Rewrite correlated subqueries using joins (e.g., EXISTS to SEMIJOIN).

- Use Indexes Strategically: Apply indexes to frequently queried columns (e.g., primary keys, join attributes).

## conclusion 

Reflecting on these lessons, I see how indexing, query processing, and optimization are key to database efficiency. Indexes like B+ trees or hashes speed up searches but require smart choices—balancing storage and speed. Multilevel indexing tackles memory limits by layering lookups, making large datasets manageable.

Query processing transforms SQL into actionable plans, with steps like parsing and pipelining. I learned to prioritize early filtering and avoid unnecessary disk writes. Cost metrics matter too; while I/O was once king, modern systems factor in CPU, especially for in-memory data.

Optimization blends rules and intuition. Rewriting queries using equivalence rules or reordering joins can slash costs. Heuristics like early selection and avoiding nested subqueries keep plans efficient.